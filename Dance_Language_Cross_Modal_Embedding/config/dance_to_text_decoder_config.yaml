# Dance-to-Text Decoder Configuration

# Device settings
device: "cuda"  # "cuda" or "cpu"

# Model parameters
bert_model_name: "bert-base-uncased"
input_dim: 256
hidden_dim: 512

# Loss function parameters
margin: 0.2

# Training parameters
batch_size: 32
learning_rate: 0.001
num_epochs: 50
lr_decay_factor: 0.5
lr_patience: 5

# Data paths
train_data_path: "data/processed/train_data.npy"
val_data_path: "data/processed/val_data.npy"
test_data_path: "data/processed/test_data.npy"

# Evaluation parameters
top_k_eval: [1]  # Evaluate top-k accuracy for these k values

# Output settings
save_path: "checkpoints/dance_to_text_decoder.pt"
results_path: "results/dance_to_text_decoder_results.json"
