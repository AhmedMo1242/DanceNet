# Text-to-Dance Decoder Configuration

# Model Configuration
model:
  n_joints: 55         # Number of joints in the motion data
  n_dims: 3            # Number of dimensions per joint (x, y, z)
  hidden_dim: 384      # Hidden dimension size for RNNs
  latent_dim: 256      # Latent vector dimension size
  n_layers: 2          # Number of layers in RNNs
  dropout: 0.3         # Dropout probability

# Training Configuration
training:
  batch_size: 64                # Batch size for training
  epochs: 50                    # Maximum number of training epochs
  learning_rate: 0.0003         # Learning rate for optimizer
  val_split: 0.1                # Validation split ratio if needed
  weight_decay: 1e-5            # L2 regularization weight
  clip_grad_norm: 1.0           # Gradient clipping norm
  early_stopping_patience: 10   # Patience for early stopping
  scheduler_patience: 5         # Patience for learning rate scheduler
  scheduler_factor: 0.5         # Factor by which to reduce learning rate
  beta: 1.0                     # Weight for KL divergence term
  alpha: 1.0                    # Weight for velocity loss term

# Data Configuration
data:
  seq_length: 50                # Motion sequence length
  train_path: "./data/train.npy"  # Path to training data
  val_path: "./data/val.npy"      # Path to validation data
  test_path: "./data/test.npy"    # Path to test data

# Paths Configuration
paths:
  model_path: "./pretrained_vae.pth"  # Path to pretrained model
  output_dir: "./outputs"             # Output directory
  checkpoint_dir: "./checkpoints"     # Checkpoint directory
  log_dir: "./logs"                   # Log directory

# Reconstructions during training
save_reconstructions_during_training: false  # Whether to save reconstructions during training
reconstruction_save_interval: 10             # Save reconstructions every N epochs

# Control options
freeze_encoder: true          # Whether to freeze the encoder during fine-tuning
initialize_randomly: false    # Whether to initialize the model randomly
