# Why This Project?

## Table of Contents
- [Why am I applying?](#why-am-i-applying)
- [My artistic background](#my-artistic-background)
- [Experience with AI and art](#experience-with-ai-and-art)
- [Benefits and drawbacks of AI in creative processes](#benefits-and-drawbacks-of-ai-in-creative-processes)
- [Collaboration preferences](#collaboration-preferences)
- [Ideas for multimodal dance representations](#ideas-for-multimodal-dance-representations)

## Why am I applying?

I have always been fascinated by research. The process of exploring new ideas and making discoveries excites me, especially when it leads to a deeper understanding of the world and especially my major AI. There's something deeply rewarding about creating something new that expands human knowledge, especially when it helps people understand the world in new ways. In high school, I attended a school for gifted students where we were required to develop scientific projects every semester. These early experiences planted a seed that has grown into an enduring passion for discovery and innovation.

My journey into formal research began in my second year of college, where I published my first paper, "DeepCat: A Deep Learning Approach to Understand Your Cat's Body Language," presented at JAC-ECC. Seeing my work recognized gave me a sense of purpose and direction. Since then, I've expanded my research horizons significantly, with three papers currently under review at international conferences (IJCNN 2025 and ISBCom 2025), including work on exercise evaluation, keystroke authentication, and edge-based safety monitoring. Beyond these, I'm actively working on two additional research projects in NLP and GANs.

When I discovered this GSoC project combining AI and dance, I was immediately drawn to its beautiful fusion of technology and artistry. The idea of using computational methods to understand dance as a form of expression resonates deeply with me. With my background in deep learning and my appreciation for artistic expression, I believe I can make meaningful contributions while learning from experts in this emerging field.

I was particularly excited to see Dr. Mariel Pettee and Dr. Ilya Vidrin as mentors. Dr. Pettee's work at Lawrence Berkeley National Laboratory represents cutting-edge AI research, while Dr. Vidrin brings the authentic perspective of a dance professor and practitioner. 

As a senior CSE student preparing to apply for master's programs this fall, this project represents a perfect stepping stone toward my academic goals. The opportunity to collaborate with established researchers could not only enhance my technical skills but also potentially lead to publications that would strengthen my graduate applications. More importantly, having the chance to work on something I genuinely love while contributing to the scientific community through open-source development would be incredibly fulfilling. Open-source collaboration has always been a value I admire, as it democratizes knowledge and invites diverse perspectives to tackle complex problems. Having mentors to guide me through rigorous research in this fascinating interdisciplinary field would be invaluable as I chart my academic path toward top-tier universities.

## My artistic background

Films have always been my window into emotions that words alone cannot express. When I watch a movie that resonates with me, it's as if the director has found a visual language for feelings I've struggled to articulate. My Letterboxd profile ([ahmedmo10](https://letterboxd.com/ahmedmo10/)) is filled with my attempts to capture these experiences, though I almost exclusively write in Arabic—my mother tongue allows me to express the nuances of emotion with a precision I can't achieve in English. These reviews aren't meant for an audience; they're conversations with myself, explorations of how cinema makes me feel in the language that feels most intimate to me.

The same emotional resonance I find in film, I recognize in other art forms. In Egyptian cafes, the melodies of Om Kalthoum and Abdel Halim Hafez flow through the air, creating an atmosphere where music isn't just heard but collectively felt. These songs, playing endlessly in the background of everyday life, become part of our emotional vocabulary—a shared language of feeling that everyone understands without needing to explain.

I even see art in places others might miss it—like football. The way Messi moves across the field, finding impossible angles and creating opportunities that weren't there a moment before, is its own form of choreography. When I wrote my piece connecting Maradona and Mozart after Diego's passing, I was trying to articulate this very thing: that genius expresses itself across disciplines in ways that feel fundamentally connected, whether through music, movement, or any other medium.

Growing up in Egypt, I've been surrounded by a rich cultural heritage that includes traditional dance forms. The goddess Hathor—our ancient deity of dance, music, and joy—represents this profound connection between movement and expression that transcends centuries. Belly dancing, in particular, is woven into the fabric of Egyptian life—appearing in wedding celebrations where entire families join in, featuring prominently in our films as cultural touchstones, and even emerging spontaneously in everyday gatherings. When I see traditional Egyptian dancers perform, there's a language being spoken through their movements that connects directly to our cultural identity and emotional landscape. The way these dancers communicate joy, celebration, and even subtle narrative through movement alone has always fascinated me.

This is why the intersection of AI and dance fascinates me so deeply. If we can build computational systems that understand the language of movement, we might preserve and extend these profound forms of human expression. Dance, like film and music, speaks truths that words alone cannot capture—and building bridges between these expressive forms and computational understanding feels like a profound and meaningful challenge.

## Experience with AI and art

My formal introduction to the intersection of AI and art came through an Art Appreciation course I took as an elective, where I earned an A+. While I initially worried the course might focus on drawing skills (which I lack), it instead explored the deeper question of what constitutes art and artistic expression across different media. Two lectures specifically addressed AI-generated art, sparking passionate debates about authorship and creativity in the digital age.

During one particularly memorable session, I presented on the film "Everything Everywhere All at Once," analyzing how the directors layered visual metaphors to represent complex emotional states that would be impossible to convey through dialogue alone. The professor and I discussed how this multilayered approach to visual storytelling mirrors what we might aim for in computational representations of art—capturing not just the surface form but the deeper emotional and conceptual structures.

In another session, I gave a presentation on Michelangelo (cleverly interspersed with Teenage Mutant Ninja Turtle memes that surprisingly delighted my professor even if it was a lame joke). This juxtaposition of Renaissance art with contemporary pop culture references illustrated how artistic expression evolves while maintaining core principles across centuries—a concept directly relevant to computational approaches to art.

One of the most thought-provoking discussions in the course centered on whether programmers who create AI art systems should be considered artists themselves. The class was divided, with compelling arguments on both sides. My position was that while the programmers aren't necessarily the artists, they're creating new artistic tools that extend human creative capabilities. The programmer/AI combination creates a new kind of collaborative artistic entity—similar to how I view the potential of AI in dance analysis and generation.

Beyond the classroom, I've experimented with using GANs to generate visual art and explored how different architectures affect the aesthetic qualities of the outputs. I've also followed the development of tools like DALL-E, Midjourney, and systems that generate music, analyzing both their technical underpinnings and artistic implications.

What fascinates me about these intersections is how AI systems, trained on human-created art, develop their own "aesthetic" that both mimics and diverges from human artistic conventions. This tension between human and machine creativity is exactly what makes the dance-AI intersection so compelling—dance is deeply human and embodied, yet its patterns and structures can potentially be captured and extended through computational means.

## Benefits and drawbacks of AI in creative processes

AI brings tremendous possibilities to creative processes. It can serve as an inspirational tool, generating unexpected variations that artists might never have considered. It excels at pattern recognition and can reveal connections between movements or styles that human analysis might miss. For dance specifically, AI offers new ways to document, analyze, and preserve choreography—potentially creating a more comprehensive record of movement traditions than has ever been possible before.

However, significant challenges exist. AI-generated content often lacks the emotional depth and intentionality that defines human artistic expression. There's a risk of over-reliance on AI tools, potentially homogenizing creative output rather than diversifying it. Ethical concerns abound, from questions of bias in training data to thorny issues of ownership when AI generates content based on existing works.

The key, I believe, lies in positioning AI as a collaborative tool that enhances human creativity rather than replacing it—allowing artists to explore new frontiers while maintaining their unique voice and vision.

## Collaboration preferences

I thrive in research environments that balance structure with flexibility. For day-to-day communication, I strongly prefer asynchronous platforms like Slack or Discord, which allow me to process information thoughtfully and respond with precision. These tools create a documented record of decisions and discussions that prove invaluable as projects evolve.

For more complex collaborative moments—brainstorming sessions, technical problem-solving, or conceptual discussions—I value synchronous video meetings, but with clear structure. I find the most productive meetings include three key components:
1. A review of what we've accomplished since the last meeting
2. A focused discussion on current challenges with visual demonstrations or proof-of-concept implementations
3. Clear next steps with defined responsibilities and deadlines

I particularly appreciate when meetings involve small "demo reports" or visual presentations rather than abstract discussions. Seeing concrete progress, even in rough form, helps ground conversations and ensures everyone has the same understanding.

Between structured touchpoints, I enjoy deep focus periods for independent work. This rhythm of independent development punctuated by collaborative check-ins allows me to make significant progress while benefiting from the team's collective intelligence at strategic moments.

I'm also a believer in transparent documentation practices—creating shared repositories of knowledge that make collaboration seamless even when team members work asynchronously across different time zones or schedules. This approach has proven especially valuable in my previous research collaborations, where team members often had conflicting schedules.

## Ideas for multimodal dance representations

Here are some approaches I'm excited to explore for representing dance in multimodal contexts:

1. **Innovative VAE Architectures**: I'd like to experiment with specialized Variational Autoencoders that better capture dance movements. Particularly promising is a 2D CNN-based approach where we treat dance sequences as "images" with time on one axis and body joints on another. This would allow the model to simultaneously learn temporal patterns (how movements flow) and spatial relationships (how body parts coordinate) while using fewer parameters than 3D approaches. The goal is to create latent spaces that meaningfully organize movements based on both technical execution and expressive qualities.

2. **Multi-Step Sequence Generation**: One of the most interesting challenges is generating complex choreographic phrases rather than isolated movements. For example, instead of just producing a "spin" or a "jump," could we generate natural sequences like "spin, then crouch, then reach upward"? This would require developing models that understand transitions between movements—perhaps by creating intermediate representations that guide the system from the end of one movement to the beginning of another, much like how dancers learn to flow between phrases.

3. **Encoder-Decoder vs. Encoder-Only Architectures**: I'm particularly interested in comparing different architectural approaches for dance-language alignment. While encoder-only models like BERT have revolutionized language understanding, encoder-decoder architectures might offer advantages for translating between modalities. I'd like to systematically compare these approaches, examining how encoder-only models might excel at embedding similar concepts closely in a shared space, while encoder-decoder models might better capture the transformational aspects between modalities, especially for generating structured dance sequences from text prompts.

4. **Labeling Efficiency Experiments**: A crucial question for practical applications is: how much labeled data do we truly need? I'm eager to conduct controlled experiments comparing performance when using different percentages (1% vs. 2% vs. 5%) of manually labeled data, with the remainder labeled through semi-supervised approaches. This would help us understand the relationship between annotation effort and model performance, potentially identifying the "sweet spot" where additional manual labeling yields diminishing returns.

5. **Classification vs. Clustering Approaches**: There's an intriguing methodological question about whether supervised classification or unsupervised clustering provides better foundations for dance-language alignment. Clustering approaches might better reveal the natural organization of movement data without imposing predefined categories, while classification approaches might create clearer categorical boundaries useful for interpretability. I'd like to develop hybrid approaches that leverage the strengths of both—perhaps using clustering to discover movement families, then refining with lightweight classification to create more precise semantic bridges to language.

6. **Vision Transformer Architectures and Projection Heads**: I'm fascinated by how we might adapt vision transformers for dance analysis. These models could process dance sequences as a series of movement tokens, similar to how they process image patches. The key question is about projection heads—the neural network layers that map different modalities into a shared space. Could simple linear projections work, or would we need more complex structures like MLPs or attention mechanisms? 

   What makes this particularly intriguing is that text transformers like GPT and BERT already understand multiple "languages" (English, code, mathematics), while vision and audio models are more specialized. Could we create a system where dance movements, text, music, and other modalities share a common space without requiring text as an intermediary translator? For example, could we generate music directly from dance, or dance directly from architectural spaces, without first converting to text descriptions? This area needs more research, but it could fundamentally change how we think about cross-modal creativity.



